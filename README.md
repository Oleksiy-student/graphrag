# GraphRAG (v1.3)

GraphRAG is an experimental **Retrieval-Augmented Generation (RAG)** pipeline written in Java.  
It combines **graph-based document storage** with **local embeddings** generated by **Qwen3 via Ollama**.

---

## Features
- ğŸ“„ **PDF/Text ingestion** â†’ documents are split into smaller chunks for indexing  
- ğŸ”— **Graph-based storage** â†’ built using [Apache TinkerPop / TinkerGraph](https://tinkerpop.apache.org/)  
- ğŸ§  **Embeddings** â†’ generated with **Qwen3 (via Ollama localhost API)**  
- ğŸ” **Retriever** â†’ vector similarity search to find relevant chunks  
- ğŸ› ï¸ Modular pipeline for plugging in additional stores or models  

---

## Requirements
- **Java 17+**
- **Maven**
- **Ollama** installed locally ([https://ollama.com](https://ollama.com))
- Model: `qwen3:4b` pulled via Ollama  
  ```bash
  ollama pull qwen3:4b
  ```

---

## Run
```bash
mvn clean compile exec:java -Dexec.mainClass="com.ok.App"
```

You should see:
- Embedding vectors printed in debug logs  
- Chunks being ingested into the graph  
- Retrieval returning best-match passages  

---

## Usage Example
**Query:**
```
What is a service dog?
```

**Retriever Output (chunk snippet):**
```
"... A therapy dog or an emotional support dog, even if classified as such by a physician, is not considered a guide or service dog within the meaning of this by-law ..."
```

---

## Roadmap / TODO
- [ ] Use Qwen3 for retrieval  
- [ ] Hook up **Supabase Vector Store** for persistent, cloud-based embeddings  
- [ ] Hook up an **LLM for query processing** (use retrieved chunks as context â†’ answer user queries)  
- [ ] Improve **chunking & formatting** for better readability  
- [ ] Add support for multiple embedding models  

---

## Version History
- **v1.3** â€“ Switched to **Qwen3 embeddings** via Ollama.
- **v1.0** â€“ Added local saving of the embedings.
- **v0.9** â€“ Added local saving of the graph
- **v0.8** â€“ Initial graphRAG pipeline with TinkerPop / TinkerGraph using tf-idf embedings.  

---

## License
MIT License â€“ feel free to use, modify, and contribute.
